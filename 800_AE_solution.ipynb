{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/8/81/Sciences_SU.png\" width=\"240\" height=\"240\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLA 801. Auto-Encodeur (en Keras, avec CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : AE-CNN sur données propres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les librairies nécessaires\n",
    "\n",
    "# Le dataset MNIST\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Les librairies TF pour le DL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,Dense, Conv2D, Conv2DTranspose, MaxPooling2D, Flatten, UpSampling2D, Reshape\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "\n",
    "# Les librairies habituelles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# On configure la session pour l'utilisation de GPU\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = tf.Session(config=config)\n",
    "\n",
    "# On désactive les warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Définition de fonctions nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_AE_disp(img_in, img_out, img_idx):\n",
    "\n",
    "    num_img = len(img_idx)\n",
    "    plt.figure(figsize=(18, 4))\n",
    "\n",
    "    for i, image_idx in enumerate(img_idx):\n",
    "        # on trace l'image originale\n",
    "        ax = plt.subplot(2, num_img, i + 1)\n",
    "        plt.imshow(img_in[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # on trace l'image bruitée\n",
    "        ax = plt.subplot(2, num_img, num_img + i + 1)\n",
    "        plt.imshow(img_out[image_idx].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Chargement et formatage des données (propres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les données de MNIST (incluses dans Keras)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# On normalise les valeurs des pixels de [0, 255] à [0, 1]\n",
    "x_train=x_train.astype('float32')/float(x_train.max())\n",
    "x_test=x_test.astype('float32')/float(x_test.max())\n",
    "\n",
    "# POUR LES CNN : On rajoute une dimension pour spécifier qu'il s'agit d'imgages en NdG\n",
    "x_train=x_train.reshape(len(x_train),x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test=x_test.reshape(len(x_test),x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "# On inspecte les dimensions de nos données\n",
    "# Base d'entrainement : 60,000 images de dimension (28,28)\n",
    "# Base de test : 10,000 images de dimension (28,28)\n",
    "print(\"Training set : \",x_train.shape)\n",
    "print(\"Testing set : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Création du réseau CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On déclare les dimensions de notre réseau\n",
    " \n",
    "############################################\n",
    "# 1) Construction de la partie \"encodeur\"  #\n",
    "############################################\n",
    "\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# 1) Partie encodeur\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# 2) Construction de la partie \"décodeur\"\n",
    "# Decoder Layers\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "#autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# On visualise la structure du réseau\n",
    "autoencoder.summary()\n",
    "\n",
    "# Compilation du réseau\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Apprentissage du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage du réseau\n",
    "history=autoencoder.fit(x_train,x_train,epochs=5, batch_size=256, shuffle=True, validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Prédiction par le réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On génère un jeu de 10 images test au hasard\n",
    "num_images=10\n",
    "np.random.seed(42)\n",
    "random_test_images=np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "# On détermine l'image encodée et l'image décodée\n",
    "decoded_img=autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) On visualise l'image d'entrée, le code, et la reconstruction\n",
    "\n",
    "# On trace l'image d'entrée et l'image décodée (reconstruite à partir du code)\n",
    "MNIST_AE_disp(x_test, decoded_img, random_test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Vers le Denoising AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Création des données bruitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On génère un jeu de 10 images test au hasard\n",
    "num_images=10\n",
    "np.random.seed(42)\n",
    "random_test_images=np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "# On génère des données bruitées\n",
    "\n",
    "# 1) Possibilité 1: Ajout de bruit additif\n",
    "x_train_noisy = x_train + np.random.normal(loc=0.0, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "\n",
    "x_test_noisy = x_test + np.random.normal(loc=0.0, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# 2) Possibilité 2 : ajout de bruit multiplicatif avec un masque binaire\n",
    "#dropout_frac = 0.15\n",
    "# On créée des masques binaires avec une certaine probabilité de 1\n",
    "#activation_train_mask = np.random.binomial(1, dropout_frac, size=x_train.shape)\n",
    "#activation_test_mask = np.random.binomial(1, dropout_frac, size=x_test.shape)\n",
    "# On applique les masques (multiplication point à point)\n",
    "#x_train_noisy = np.multiply(x_train, activation_train_mask)\n",
    "#x_test_noisy = np.multiply(x_test, activation_test_mask)\n",
    "\n",
    "# On visualise les données\n",
    "\n",
    "MNIST_AE_disp(x_train, x_train_noisy, random_test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prédictions à partir des données bruitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même chose mais avec les données bruitées\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "# Denoise test images\n",
    "x_test_denoised = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "# On visualise les données\n",
    "MNIST_AE_disp(x_test_noisy, x_test_denoised, random_test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Apprentissage du réseaux DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ré-apprend le réseau mais en mode denoiser ...\n",
    "\n",
    "# Apprentissage du réseau\n",
    "history=autoencoder.fit(x_train_noisy,x_train,epochs=5, batch_size=256, shuffle=True, validation_data=(x_test_noisy,x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Prédiction et visualisation à partir des données bruitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On génère un jeu de 10 images test au hasard\n",
    "num_images=10\n",
    "np.random.seed(42)\n",
    "random_test_images=np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "# On détermine l'image encodée et l'image décodée\n",
    "decoded_img=autoencoder.predict(x_test)\n",
    "\n",
    "# Même chose mais avec les données bruitées\n",
    "MNIST_AE_disp(x_test_noisy, decoded_img, random_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
