{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d'apprentissage d'un réseau de neurones par héritage de la classe Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des données d'apprentissage\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "Y = np.array([0,1,1,0])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (X, Y)).shuffle(10000).batch(1)\n",
    "\n",
    "# ATTENTION : on utilise les données d'apprentissage en test\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "(X, Y)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tous les réseaux doivent hériter de la classe Model \n",
    "class XorModel(Model):\n",
    "\n",
    "    # Dans le coinstructeur, on définit sa structure, i.e. les éléments constitutifs du graph\n",
    "    def __init__(self):\n",
    "        super(XorModel, self).__init__()\n",
    "        self.fc1 = Dense(2, activation='sigmoid')\n",
    "        self.fc2 = Dense(1, activation='sigmoid')\n",
    "    \n",
    "    # Définition des traitements des lors de la propagation d’un exemple x dans le réseaux\n",
    "    # (i.e. la manière dont les éléments du graphe sont connectés)\n",
    "    # A noter qu'il n'est pas necessaire de suivre l'ordre des opérations défini dans le constructeur.\n",
    "    # Cette solution est donc beaucoup plus souple que le modél sequentiel précédent\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une instance du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_model = XorModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix de la fonction de coût et de la méthode d'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la fonction d'apprentissage qui sera applelée pour chaque step (pas) d'apprentissage (pour un batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(data, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # forward pass\n",
    "        predictions = xor_model(data)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    # calcul des gradients\n",
    "    gradient = tape.gradient(loss, xor_model.trainable_variables)\n",
    "    # retropropagation\n",
    "    sgd.apply_gradients(zip(gradient, xor_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "for epoch in range(EPOCHS):\n",
    "    for data, labels in train_ds:\n",
    "        train_step(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On visualise les résultats (sur les données d'apprentissage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(-0.1, 1.1, 0.05):\n",
    "    for j in np.arange(-0.1, 1.1, 0.05):\n",
    "        z = xor_model(np.array([[i,j]]))\n",
    "        if z>0.5 :\n",
    "            plt.plot(i,j,'.r')\n",
    "        else :\n",
    "            plt.plot(i,j, '.b')\n",
    "\n",
    "# Affichage de la base d'apprentissage\n",
    "for i in range(Y.size) :\n",
    "    if Y[i] == 1 :\n",
    "        fig = plt.plot(X[i,0], X[i,1], 'ro')\n",
    "    else :\n",
    "        fig = plt.plot(X[i, 0], X[i, 1], 'bo')\n",
    "    plt.setp(fig, markersize=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
